{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Conv2D, Dropout, MaxPool2D, Flatten\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col=0)\n",
    "test = pd.read_csv('test.csv', index_col=0)\n",
    "submission = pd.read_csv('sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = train.iloc[:,:1]\n",
    "\n",
    "x2 = train.iloc[:,1:36]\n",
    "\n",
    "x3 = train.iloc[:,36:71]\n",
    "\n",
    "y1 = train.iloc[:,71:72]\n",
    "\n",
    "y2 = train.iloc[:,72:73]\n",
    "\n",
    "y3 = train.iloc[:,73:74]\n",
    "\n",
    "y4 = train.iloc[:,74:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.iloc[:,71:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.iloc[:,:1]\n",
    "\n",
    "test2 = test.iloc[:,1:36]\n",
    "\n",
    "test3 = test.iloc[:,36:71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.interpolate(axis=0)\n",
    "x2 = x2.interpolate(axis=0)\n",
    "x3 = x3.interpolate(axis=0)\n",
    "\n",
    "test1 = test1.interpolate(axis=0)\n",
    "test2 = test2.interpolate(axis=0)\n",
    "test3 = test3.interpolate(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.fillna(x1.mean())\n",
    "x2 = x2.fillna(x2.mean())\n",
    "x3 = x3.fillna(x3.mean())\n",
    "\n",
    "test1 = test1.fillna(test1.mean())\n",
    "test2 = test2.fillna(test2.mean())\n",
    "test3 = test3.fillna(test3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.merge(x1,x2, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.merge(x,x3, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test1,test2, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test,test3, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(x) \n",
    "x = scaler.transform(x)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=12)\n",
    "# pca.fit(x)\n",
    "# x = pca.transform(x)\n",
    "# x_predict = pca.transform(x_predict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train = np.array(train)\n",
    "x_predict = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(x) \n",
    "# x = scaler.transform(x)\n",
    "# x_predict = scaler.transform(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.4567685749999995\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=43)\n",
    "model = RandomForestRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.4558895343750011\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=43)\n",
    "model1 = RandomForestRegressor(n_estimators=400)\n",
    "model1.fit(x_train,y_train)\n",
    "y_pred = model1.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.4559350049999988\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=43)\n",
    "model1 = RandomForestRegressor(n_estimators=500)\n",
    "model1.fit(x_train,y_train)\n",
    "y_pred = model1.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.456657477083331\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=43)\n",
    "model1 = RandomForestRegressor(n_estimators=600)\n",
    "model1.fit(x_train,y_train)\n",
    "y_pred = model1.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.456359540625\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=43)\n",
    "model1 = RandomForestRegressor(n_estimators=800)\n",
    "model1.fit(x_train,y_train)\n",
    "y_pred = model1.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.4558969662499988\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=43)\n",
    "model1 = RandomForestRegressor(n_estimators=1000)\n",
    "model1.fit(x_train,y_train)\n",
    "y_pred = model1.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.28733325\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y1, test_size=0.2, random_state=43)\n",
    "model = RandomForestRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 0.7106247999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 2.189337916666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.409982683333333\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y2, test_size=0.2, random_state=43)\n",
    "model = RandomForestRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y3, test_size=0.2, random_state=43)\n",
    "model = RandomForestRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y4, test_size=0.2, random_state=43)\n",
    "model = RandomForestRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor mae 는 1.497140941230232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor mae 는 0.7330654852551607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor mae 는 2.2622474812725515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor mae 는 1.4208537674215866\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y1, test_size=0.2, random_state=43)\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y2, test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y3, test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y4, test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor mae 는 1.5842333605510353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor mae 는 0.7352794179255832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor mae 는 2.30840271440237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor mae 는 1.4268806905899483\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y1, test_size=0.2, random_state=43)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y2, test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y3, test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y4, test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost mae 는 1.2829265556406977\n",
      "xgboost mae 는 0.7349076338338851\n",
      "xgboost mae 는 2.2790482931423184\n",
      "xgboost mae 는 1.4711147229343653\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y1, test_size=0.2, random_state=43)\n",
    "\n",
    "model = XGBRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y2, test_size=0.2, random_state=43)\n",
    "model = XGBRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) \n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y3, test_size=0.2, random_state=43)\n",
    "model = XGBRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y4, test_size=0.2, random_state=43)\n",
    "model = XGBRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost mae 는 1.2820630119055512\n",
      "xgboost mae 는 0.7403602701973914\n",
      "xgboost mae 는 2.2971251027679447\n",
      "xgboost mae 는 1.4673154745697976\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y1, test_size=0.2, random_state=43)\n",
    "\n",
    "model = XGBRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y2, test_size=0.2, random_state=43)\n",
    "model = XGBRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) \n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y3, test_size=0.2, random_state=43)\n",
    "model = XGBRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y4, test_size=0.2, random_state=43)\n",
    "model = XGBRegressor(n_estimators=300)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = joblib.load('./model_save/mae78.17250055599212.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출\n",
    "# pred = model1.predict(test)\n",
    "\n",
    "pred = model1.predict(test)\n",
    "submission = pd.read_csv('sample_submission.csv', index_col=0)\n",
    "submission['hhb'] = pred[:,0]\n",
    "submission['hbo2'] = pred[:,1]\n",
    "submission['ca'] = pred[:,2]\n",
    "submission['na'] = pred[:,3]\n",
    "\n",
    "submission.to_csv('submission0622_1.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pred = model1.predict(x_predict1)\n",
    "submission['hhb'] = pred[:,0]\n",
    "submission['hbo2'] = pred[:,1]\n",
    "submission['ca'] = pred[:,2]\n",
    "submission['na'] = pred[:,3]\n",
    "submission.to_csv('submission1_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhb</th>\n",
       "      <th>hbo2</th>\n",
       "      <th>ca</th>\n",
       "      <th>na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>7.330</td>\n",
       "      <td>3.861</td>\n",
       "      <td>7.608</td>\n",
       "      <td>2.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>6.530</td>\n",
       "      <td>3.993</td>\n",
       "      <td>6.310</td>\n",
       "      <td>2.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>11.439</td>\n",
       "      <td>4.057</td>\n",
       "      <td>9.335</td>\n",
       "      <td>3.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>8.239</td>\n",
       "      <td>4.599</td>\n",
       "      <td>9.715</td>\n",
       "      <td>3.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>8.279</td>\n",
       "      <td>3.615</td>\n",
       "      <td>9.837</td>\n",
       "      <td>4.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>6.134</td>\n",
       "      <td>4.480</td>\n",
       "      <td>9.480</td>\n",
       "      <td>3.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>7.258</td>\n",
       "      <td>4.027</td>\n",
       "      <td>9.550</td>\n",
       "      <td>3.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>9.724</td>\n",
       "      <td>3.333</td>\n",
       "      <td>9.786</td>\n",
       "      <td>3.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>9.455</td>\n",
       "      <td>4.714</td>\n",
       "      <td>11.051</td>\n",
       "      <td>2.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>6.110</td>\n",
       "      <td>4.011</td>\n",
       "      <td>9.873</td>\n",
       "      <td>3.264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hhb   hbo2      ca     na\n",
       "id                                 \n",
       "10000   7.330  3.861   7.608  2.890\n",
       "10001   6.530  3.993   6.310  2.105\n",
       "10002  11.439  4.057   9.335  3.524\n",
       "10003   8.239  4.599   9.715  3.084\n",
       "10004   8.279  3.615   9.837  4.130\n",
       "...       ...    ...     ...    ...\n",
       "19995   6.134  4.480   9.480  3.342\n",
       "19996   7.258  4.027   9.550  3.275\n",
       "19997   9.724  3.333   9.786  3.206\n",
       "19998   9.455  4.714  11.051  2.773\n",
       "19999   6.110  4.011   9.873  3.264\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
