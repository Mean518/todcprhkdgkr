{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Conv2D, Dropout, MaxPool2D, Flatten\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 75)\n",
      "(10000, 71)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', index_col=0)\n",
    "test = pd.read_csv('test.csv', index_col=0)\n",
    "submission = pd.read_csv('sample_submission.csv', index_col=0)\n",
    "\n",
    "train = train.interpolate()\n",
    "test = test.interpolate()\n",
    "\n",
    "train = train.fillna(train.mean())\n",
    "test = test.fillna(train.mean())\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train = np.array(train)\n",
    "x_predict = np.array(test)\n",
    "\n",
    "x = train[:,:71]\n",
    "y = train[:,71:]\n",
    "\n",
    "# 전처리\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(x) \n",
    "x = scaler.transform(x)\n",
    "x_predict = scaler.transform(x_predict)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=12)\n",
    "# pca.fit(x)\n",
    "# x = pca.transform(x)\n",
    "# x_predict = pca.transform(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(x) \n",
    "# x = scaler.transform(x)\n",
    "# x_predict = scaler.transform(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.4601283828124996\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=43)\n",
    "model = RandomForestRegressor(n_estimators=160)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.59,  0.  , 10.64, ...,  9.84,  6.38,  9.35])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(y.shape[1]) :\n",
    "    a.append(y[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 5.59,  0.  , 10.64, ...,  9.84,  6.38,  9.35]),\n",
       " array([4.32, 2.83, 3.  , ..., 3.2 , 4.06, 4.34]),\n",
       " array([ 8.92,  7.25,  8.4 , ..., 10.45, 11.28,  9.73]),\n",
       " array([4.29, 4.64, 5.16, ..., 2.06, 4.03, 3.54])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor mae 는 1.5838840045681222\n",
      "GradientBoostingRegressor mae 는 0.7350616301783675\n",
      "GradientBoostingRegressor mae 는 2.308885373741608\n",
      "GradientBoostingRegressor mae 는 1.4267326043872253\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,a[0], test_size=0.2, random_state=43)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[1], test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[2], test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[3], test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,a[0], test_size=0.2, random_state=43)\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[1], test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[2], test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[3], test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.837030398551365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(y)\n",
    "y1 = pca.transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y1, test_size=0.2, random_state=43)\n",
    "model = GradientBoostingRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('GradientBoostingRegressor mae 는', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost mae 는 1.2829265556406977\n",
      "xgboost mae 는 0.7349076338338851\n",
      "xgboost mae 는 2.2790482931423184\n",
      "xgboost mae 는 1.4711147229343653\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,a[0], test_size=0.2, random_state=43)\n",
    "\n",
    "model = XGBRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[1], test_size=0.2, random_state=43)\n",
    "model = XGBRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) \n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[2], test_size=0.2, random_state=43)\n",
    "model = XGBRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[3], test_size=0.2, random_state=43)\n",
    "model = XGBRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost mae 는 1.283430913808942\n",
      "xgboost mae 는 0.7389190593361854\n",
      "xgboost mae 는 2.2966433312320707\n",
      "xgboost mae 는 1.4670573375791311\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,a[0], test_size=0.2, random_state=43)\n",
    "\n",
    "model = XGBRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[1], test_size=0.2, random_state=43)\n",
    "model = XGBRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) \n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[2], test_size=0.2, random_state=43)\n",
    "model = XGBRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[3], test_size=0.2, random_state=43)\n",
    "model = XGBRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost mae 는 1.8154817496832283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(y)\n",
    "y1 = pca.transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y1, test_size=0.2, random_state=43)\n",
    "model = XGBRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) # 회귀던 분류던 사용할 수 있음\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('xgboost mae 는', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost mae 는 1.289325675\n",
      "xgboost mae 는 0.7111221249999999\n",
      "xgboost mae 는 2.187418975\n",
      "xgboost mae 는 1.407558775\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,a[0], test_size=0.2, random_state=43)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('RandomForestRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[1], test_size=0.2, random_state=43)\n",
    "model = RandomForestRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) \n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('RandomForestRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[2], test_size=0.2, random_state=43)\n",
    "model = RandomForestRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('RandomForestRegressor mae 는', mae)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,a[3], test_size=0.2, random_state=43)\n",
    "model = RandomForestRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('RandomForestRegressor mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.4622248984374993\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=43)\n",
    "model = RandomForestRegressor(n_estimators=160)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) \n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.7716422312499989\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=43)\n",
    "model = RandomForestRegressor(n_estimators=200)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) \n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 mae 는 1.441592375\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=20)\n",
    "model1 = RandomForestRegressor(n_estimators=250)\n",
    "model1.fit(x_train,y_train)\n",
    "y_pred = model1.predict(x_test) \n",
    "mae = mean_absolute_error(y_pred, y_test)\n",
    "print('랜덤포레스트 mae 는', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model1.predict(x_predict)\n",
    "submission = pd.read_csv('sample_submission.csv', index_col=0)\n",
    "submission['hhb'] = pred[:,0]\n",
    "submission['hbo2'] = pred[:,1]\n",
    "submission['ca'] = pred[:,2]\n",
    "submission['na'] = pred[:,3]\n",
    "\n",
    "('sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출\n",
    "pred = model1.predict(x_predict)\n",
    "\n",
    "pred = model1.predict(x_predict)\n",
    "submission = pd.read_csv('sample_submission.csv', index_col=0)\n",
    "submission['hhb'] = pred[:,0]\n",
    "submission['hbo2'] = pred[:,1]\n",
    "submission['ca'] = pred[:,2]\n",
    "submission['na'] = pred[:,3]\n",
    "\n",
    "submission.to_csv('submission0611_1.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pred = model1.predict(x_predict1)\n",
    "submission['hhb'] = pred[:,0]\n",
    "submission['hbo2'] = pred[:,1]\n",
    "submission['ca'] = pred[:,2]\n",
    "submission['na'] = pred[:,3]\n",
    "submission.to_csv('submission1_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhb</th>\n",
       "      <th>hbo2</th>\n",
       "      <th>ca</th>\n",
       "      <th>na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>7.330</td>\n",
       "      <td>3.861</td>\n",
       "      <td>7.608</td>\n",
       "      <td>2.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>6.530</td>\n",
       "      <td>3.993</td>\n",
       "      <td>6.310</td>\n",
       "      <td>2.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>11.439</td>\n",
       "      <td>4.057</td>\n",
       "      <td>9.335</td>\n",
       "      <td>3.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>8.239</td>\n",
       "      <td>4.599</td>\n",
       "      <td>9.715</td>\n",
       "      <td>3.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>8.279</td>\n",
       "      <td>3.615</td>\n",
       "      <td>9.837</td>\n",
       "      <td>4.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>6.134</td>\n",
       "      <td>4.480</td>\n",
       "      <td>9.480</td>\n",
       "      <td>3.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>7.258</td>\n",
       "      <td>4.027</td>\n",
       "      <td>9.550</td>\n",
       "      <td>3.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>9.724</td>\n",
       "      <td>3.333</td>\n",
       "      <td>9.786</td>\n",
       "      <td>3.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>9.455</td>\n",
       "      <td>4.714</td>\n",
       "      <td>11.051</td>\n",
       "      <td>2.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>6.110</td>\n",
       "      <td>4.011</td>\n",
       "      <td>9.873</td>\n",
       "      <td>3.264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hhb   hbo2      ca     na\n",
       "id                                 \n",
       "10000   7.330  3.861   7.608  2.890\n",
       "10001   6.530  3.993   6.310  2.105\n",
       "10002  11.439  4.057   9.335  3.524\n",
       "10003   8.239  4.599   9.715  3.084\n",
       "10004   8.279  3.615   9.837  4.130\n",
       "...       ...    ...     ...    ...\n",
       "19995   6.134  4.480   9.480  3.342\n",
       "19996   7.258  4.027   9.550  3.275\n",
       "19997   9.724  3.333   9.786  3.206\n",
       "19998   9.455  4.714  11.051  2.773\n",
       "19999   6.110  4.011   9.873  3.264\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
